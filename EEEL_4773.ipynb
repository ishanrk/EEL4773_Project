{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c343dcb",
   "metadata": {},
   "source": [
    "# Dependencies Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60261ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kumth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     ArrowDtype,\n\u001b[0;32m     62\u001b[0m     Int8Dtype,\n\u001b[0;32m     63\u001b[0m     Int16Dtype,\n\u001b[0;32m     64\u001b[0m     Int32Dtype,\n\u001b[0;32m     65\u001b[0m     Int64Dtype,\n\u001b[0;32m     66\u001b[0m     UInt8Dtype,\n\u001b[0;32m     67\u001b[0m     UInt16Dtype,\n\u001b[0;32m     68\u001b[0m     UInt32Dtype,\n\u001b[0;32m     69\u001b[0m     UInt64Dtype,\n\u001b[0;32m     70\u001b[0m     Float32Dtype,\n\u001b[0;32m     71\u001b[0m     Float64Dtype,\n\u001b[0;32m     72\u001b[0m     CategoricalDtype,\n\u001b[0;32m     73\u001b[0m     PeriodDtype,\n\u001b[0;32m     74\u001b[0m     IntervalDtype,\n\u001b[0;32m     75\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     76\u001b[0m     StringDtype,\n\u001b[0;32m     77\u001b[0m     BooleanDtype,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     NA,\n\u001b[0;32m     80\u001b[0m     isna,\n\u001b[0;32m     81\u001b[0m     isnull,\n\u001b[0;32m     82\u001b[0m     notna,\n\u001b[0;32m     83\u001b[0m     notnull,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     Index,\n\u001b[0;32m     86\u001b[0m     CategoricalIndex,\n\u001b[0;32m     87\u001b[0m     RangeIndex,\n\u001b[0;32m     88\u001b[0m     MultiIndex,\n\u001b[0;32m     89\u001b[0m     IntervalIndex,\n\u001b[0;32m     90\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     91\u001b[0m     DatetimeIndex,\n\u001b[0;32m     92\u001b[0m     PeriodIndex,\n\u001b[0;32m     93\u001b[0m     IndexSlice,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     NaT,\n\u001b[0;32m     96\u001b[0m     Period,\n\u001b[0;32m     97\u001b[0m     period_range,\n\u001b[0;32m     98\u001b[0m     Timedelta,\n\u001b[0;32m     99\u001b[0m     timedelta_range,\n\u001b[0;32m    100\u001b[0m     Timestamp,\n\u001b[0;32m    101\u001b[0m     date_range,\n\u001b[0;32m    102\u001b[0m     bdate_range,\n\u001b[0;32m    103\u001b[0m     Interval,\n\u001b[0;32m    104\u001b[0m     interval_range,\n\u001b[0;32m    105\u001b[0m     DateOffset,\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     to_numeric,\n\u001b[0;32m    108\u001b[0m     to_datetime,\n\u001b[0;32m    109\u001b[0m     to_timedelta,\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     Flags,\n\u001b[0;32m    112\u001b[0m     Grouper,\n\u001b[0;32m    113\u001b[0m     factorize,\n\u001b[0;32m    114\u001b[0m     unique,\n\u001b[0;32m    115\u001b[0m     value_counts,\n\u001b[0;32m    116\u001b[0m     NamedAgg,\n\u001b[0;32m    117\u001b[0m     array,\n\u001b[0;32m    118\u001b[0m     Categorical,\n\u001b[0;32m    119\u001b[0m     set_eng_float_format,\n\u001b[0;32m    120\u001b[0m     Series,\n\u001b[0;32m    121\u001b[0m     DataFrame,\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\kumth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kumth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.optim.lr_scheduler import StepLR    # learning rate scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bebccf",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285c2c2",
   "metadata": {},
   "source": [
    "The class below represents our final model and an instance of it is initialized with our tuned hyperparameters\n",
    "\n",
    "The convolutional layers of the model can be changed by giving an argument of a list with kernel size, number of filters, and dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, \n",
    "                 #conv_filters=[32, 64, 128],\n",
    "                 #kernel_sizes=[3,3,3], \n",
    "                 #dropout_rate=0.5\n",
    "                 conv_layers = [{\"out_ch\":32, \"kernel_size\":5, \"dropout_rate\":0.5},\n",
    "                                {\"out_ch\":64, \"kernel_size\":5, \"dropout_rate\":0.5},\n",
    "                                {\"out_ch\":128, \"kernel_size\":5, \"dropout_rate\":0.5}],\n",
    "                mlp_layers = {\"out_ch\":256, \"dropout_rate\":0.5}\n",
    "                 ):\n",
    "        super(ImageCNN, self).__init__()\n",
    "        layers = []\n",
    "        in_ch = 1  # single-channel input\n",
    "        for spec in conv_layers:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, spec[\"out_ch\"], kernel_size=spec[\"kernel_size\"], padding='same'),\n",
    "                nn.BatchNorm2d(spec[\"out_ch\"]),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout2d(spec[\"dropout_rate\"]),\n",
    "            ]\n",
    "            in_ch = spec[\"out_ch\"]  # update input channels for next layer\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample = torch.zeros(1,1,100,100)\n",
    "            feat = self.conv(sample)\n",
    "        flat_dim = feat.view(1, -1).size(1)\n",
    "        self.fc1 = nn.Linear(flat_dim, mlp_layers[\"out_ch\"])\n",
    "        self.bn1 = nn.BatchNorm1d(mlp_layers[\"out_ch\"])\n",
    "        self.dropout = nn.Dropout(mlp_layers[\"dropout_rate\"])\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)                 # (batch, C, H, W)\n",
    "        x = x.view(x.size(0), -1)        # flatten\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)              # (batch, 256)\n",
    "        # x = self.mlp(x)                 # (batch, num_classes)\n",
    "        x = self.fc2(x)                 # (batch, num_classes)\n",
    "        return x\n",
    "\n",
    "    # Kaiming weight init\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "# Model Instance and tuned hyperparameters\n",
    "conv_layers = [\n",
    "                {\"out_ch\":16, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":32, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":64, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":128, \"kernel_size\": 7, \"dropout_rate\": 0.3}\n",
    "                \n",
    "            ]\n",
    "model = ImageCNN(conv_layers=conv_layers, mlp_layers={\"out_ch\":256, \"dropout_rate\":0.5}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cf4ae",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d80a0d",
   "metadata": {},
   "source": [
    "The cell below contains the main train function that can be run with different batch sizes, learning rates and epochs.\n",
    "\n",
    "It needs a matrix (np array) x_train with the feature data and a label vector y_train (np array) to train correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a580a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentations\n",
    "def get_augmented_transforms():\n",
    "     return transforms.Compose([\n",
    "         transforms.ToPILImage(),             # expects CxHxW or HxW\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(degrees=15),\n",
    "         transforms.RandomResizedCrop(size=100, scale=(0.8, 1.0)),\n",
    "         transforms.ToTensor(),               # gets 1x100x100 for 1 channel\n",
    "     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, x_train, y_train , epochs=25, lr=1e-3, batch_size = 64, device=None):\n",
    "\n",
    "    X = x_train.reshape(-1, 100, 100)  # reshape to (N, 100, 100)\n",
    "    X = X / 255.0  # normalize if needed\n",
    "    X = X[:, np.newaxis, :, :]  # add channel dim: (N, 1, 100, 100)\n",
    "    #  to tensors\n",
    "    X_train_tensor = torch.from_numpy(X)\n",
    "    y_train_tensor = torch.from_numpy(y_train)\n",
    "\n",
    "    augment = get_augmented_transforms()\n",
    "    augmented_imgs = torch.stack([augment(img) for img in X_train_tensor])\n",
    "\n",
    "\n",
    "    X_train_tensor = torch.cat([X_train_tensor, augmented_imgs], dim=0)\n",
    "\n",
    "    y_train_tensor = torch.cat([y_train_tensor, y_train_tensor], dim=0)\n",
    "\n",
    "    train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # create loader\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # lr ← lr * 0.1 every 10 epochs\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # training\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "        avg_train_loss = train_loss / total\n",
    "        train_acc = correct / total * 100\n",
    "\n",
    "        # for keeping track\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        scheduler.step()  # update learning rate\n",
    "        print(f\"Epoch {epoch}/{epochs} — \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Training Accuracy: {train_acc:.2f}% | \"\n",
    "              f\" — Current Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0db5ab",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d625b9",
   "metadata": {},
   "source": [
    "The test function below requires a trained model, a matrix (np array) x_test and a label vector y_test (np array)\n",
    "\n",
    "It outputs an array predictions and a test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaba1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test):\n",
    "    '''\n",
    "    Takes in two numpy arrays for features: x_test\n",
    "    and for labels: y_test\n",
    "    and outputs a vector of predictions,\n",
    "    and accuracy\n",
    "    '''\n",
    "    X = x_test\n",
    "    X = X.reshape(-1, 100, 100)\n",
    " \n",
    "    X /= 255.0\n",
    "\n",
    "    X = X[:, np.newaxis, :, :]  # add channel dim: (N, 1, 100, 100)\n",
    "    #  to tensors\n",
    "    X_tensor = torch.from_numpy(X)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = model(X_tensor.to(device=device))\n",
    "\n",
    "    preds =  preds.argmax(dim=1)\n",
    "\n",
    "    accuracy = np.sum(preds.cpu().numpy()==y_test)/len(y_test)\n",
    "    print(\"Accuracy is: \", accuracy)\n",
    "    return preds, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad5d00",
   "metadata": {},
   "source": [
    "# Sample Test\n",
    "\n",
    "This is a sample test, to show how we train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [\n",
    "                {\"out_ch\":16, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":32, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":64, \"kernel_size\": 7, \"dropout_rate\": 0.3},\n",
    "        {\"out_ch\":128, \"kernel_size\": 7, \"dropout_rate\": 0.3}\n",
    "                \n",
    "            ]\n",
    "model = ImageCNN(conv_layers=conv_layers, mlp_layers={\"out_ch\":256, \"dropout_rate\":0.5})\n",
    "\n",
    "feats_csv = 'x_train_project.csv'   \n",
    "labels_csv = 't_train_project.csv'\n",
    "\n",
    "x_train = pd.read_csv(feats_csv, header=None).values.astype(np.float32)\n",
    "y_train = pd.read_csv(labels_csv, header=None).values.squeeze().astype(np.int64)\n",
    "\n",
    "# train\n",
    "history = train(model, x_train, y_train, epochs=25, lr=1e-2)\n",
    "# expect high accuracy as testing on same data\n",
    "predictions, accuracy = test(model, x_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
